{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756b1459-3729-4342-97ff-c817d510c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import quote_plus\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549ce14d-ac19-4d80-9659-be4b2c8ad35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sysdiagrams',), ('dim_Stance',), ('dim_Referee',), ('dim_FinishType',), ('dim_Date',), ('dim_Event',), ('dim_Fighter',), ('fact_Fight',)]\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect(\n",
    "    r\"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "    r\"SERVER=DESKTOP-MLG7MPI\\MSSQLSERVER01;\"\n",
    "    r\"DATABASE=UFCStorage;\"\n",
    "    r\"UID=administrator;\"\n",
    "    r\"PWD=administrator;\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sys.tables\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e3f4d41-65bc-480a-b2a5-20ef3e7a04c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the connection string\n",
    "username = \"administrator\"\n",
    "password = \"administrator\"\n",
    "server = \"DESKTOP-MLG7MPI\\MSSQLSERVER01\"\n",
    "database = \"UFCStorage\"\n",
    "\n",
    "# Properly encode the connection string\n",
    "params = quote_plus(\n",
    "    f\"DRIVER=ODBC Driver 17 for SQL Server;\"\n",
    "    f\"SERVER={server};\"\n",
    "    f\"DATABASE={database};\"\n",
    "    f\"UID={username};\"\n",
    "    f\"PWD={password};\"\n",
    ")\n",
    "\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733ec180-7cce-43f5-b4dd-5363a2b9aede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fightID</th>\n",
       "      <th>fighterRedID</th>\n",
       "      <th>fighterBlueID</th>\n",
       "      <th>winner</th>\n",
       "      <th>fighterID</th>\n",
       "      <th>rWins</th>\n",
       "      <th>rLosses</th>\n",
       "      <th>rDraws</th>\n",
       "      <th>rHeight</th>\n",
       "      <th>rReach</th>\n",
       "      <th>...</th>\n",
       "      <th>bHeight</th>\n",
       "      <th>bReach</th>\n",
       "      <th>bWeight</th>\n",
       "      <th>bStanceID</th>\n",
       "      <th>bSigStrAcc</th>\n",
       "      <th>bSigStrDef</th>\n",
       "      <th>bTdAcc</th>\n",
       "      <th>bTdDef</th>\n",
       "      <th>bAvgSubAtt</th>\n",
       "      <th>bDOB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>969</td>\n",
       "      <td>1151</td>\n",
       "      <td>B</td>\n",
       "      <td>969</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>62</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>19920629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2445</td>\n",
       "      <td>3599</td>\n",
       "      <td>R</td>\n",
       "      <td>2445</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>182</td>\n",
       "      <td>187</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>19931213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1139</td>\n",
       "      <td>1505</td>\n",
       "      <td>R</td>\n",
       "      <td>1139</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>185</td>\n",
       "      <td>193</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>19920118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1135</td>\n",
       "      <td>932</td>\n",
       "      <td>R</td>\n",
       "      <td>1135</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>170</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>20001220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>580</td>\n",
       "      <td>653</td>\n",
       "      <td>B</td>\n",
       "      <td>580</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>182</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>19960904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7401</th>\n",
       "      <td>7402</td>\n",
       "      <td>2027</td>\n",
       "      <td>3912</td>\n",
       "      <td>R</td>\n",
       "      <td>2027</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>187</td>\n",
       "      <td>192</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7402</th>\n",
       "      <td>7403</td>\n",
       "      <td>2966</td>\n",
       "      <td>3104</td>\n",
       "      <td>R</td>\n",
       "      <td>2966</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>190</td>\n",
       "      <td>195</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403</th>\n",
       "      <td>7404</td>\n",
       "      <td>3223</td>\n",
       "      <td>2212</td>\n",
       "      <td>R</td>\n",
       "      <td>3223</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>195</td>\n",
       "      <td>200</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7404</th>\n",
       "      <td>7405</td>\n",
       "      <td>3506</td>\n",
       "      <td>3565</td>\n",
       "      <td>R</td>\n",
       "      <td>3506</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>192</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>182</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7405</th>\n",
       "      <td>7406</td>\n",
       "      <td>2354</td>\n",
       "      <td>3497</td>\n",
       "      <td>R</td>\n",
       "      <td>2354</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>182</td>\n",
       "      <td>187</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7406 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fightID  fighterRedID  fighterBlueID winner  fighterID  rWins  rLosses  \\\n",
       "0           1           969           1151      B        969     12        4   \n",
       "1           2          2445           3599      R       2445      9        1   \n",
       "2           3          1139           1505      R       1139     12        4   \n",
       "3           4          1135            932      R       1135      7        0   \n",
       "4           5           580            653      B        580     18        5   \n",
       "...       ...           ...            ...    ...        ...    ...      ...   \n",
       "7401     7402          2027           3912      R       2027      1        5   \n",
       "7402     7403          2966           3104      R       2966      1        0   \n",
       "7403     7404          3223           2212      R       3223      2        1   \n",
       "7404     7405          3506           3565      R       3506     20       17   \n",
       "7405     7406          2354           3497      R       2354      2        1   \n",
       "\n",
       "      rDraws  rHeight  rReach  ...  bHeight  bReach  bWeight  bStanceID  \\\n",
       "0          0      160     167  ...      165     165       56          3   \n",
       "1          0      190     200  ...      182     187      119          4   \n",
       "2          0      187     190  ...      185     193       83          3   \n",
       "3          0      177     177  ...      172     170       61          4   \n",
       "4          0      177     177  ...      177     182       61          5   \n",
       "...      ...      ...     ...  ...      ...     ...      ...        ...   \n",
       "7401       0      177     182  ...      187     192      111          3   \n",
       "7402       0      178     182  ...      190     195       95          3   \n",
       "7403       0      182     187  ...      195     200      124          3   \n",
       "7404       0      187     192  ...      178     182       77          3   \n",
       "7405       0      177     182  ...      182     187       79          3   \n",
       "\n",
       "      bSigStrAcc  bSigStrDef  bTdAcc  bTdDef  bAvgSubAtt        bDOB  \n",
       "0             40          62      48      60           0  19920629.0  \n",
       "1             55          49       0     100           0  19931213.0  \n",
       "2             47          47      75      64           0  19920118.0  \n",
       "3             46          55      36      44           0  20001220.0  \n",
       "4             48          64      31      60           1  19960904.0  \n",
       "...          ...         ...     ...     ...         ...         ...  \n",
       "7401           0           0       0       0           0         NaN  \n",
       "7402           0           0       0       0           0         NaN  \n",
       "7403           0           0       0       0           0         NaN  \n",
       "7404           0           0       0       0           0         NaN  \n",
       "7405           0           0       0       0           0         NaN  \n",
       "\n",
       "[7406 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM \n",
    "(\n",
    "\tSELECT fightID, fighterRedID, fighterBlueID, winner \n",
    "\tFROM fact_Fight\n",
    ") AS t\n",
    "INNER JOIN \n",
    "(\n",
    "\tSELECT \n",
    "\t\tfighterID, wins as rWins, losses as rLosses, draws as rDraws, \n",
    "\t\theight as rHeight, reach as rReach, weight as rWeight,\n",
    "\t\tstanceID as rStanceID,\n",
    "\t\tsigStrAcc as rSigStrAcc, sigStrDef as rSigStrDef, \n",
    "\t\ttdAcc as rTdAcc, tdDef as rTdDef, avgSubAtt as rAvgSubAtt,\n",
    "\t\tdateOfBirth as rDOB\n",
    "\tFROM dim_Fighter\n",
    ") AS r\n",
    "ON fighterRedID = r.fighterID\n",
    "INNER JOIN \n",
    "(\n",
    "\tSELECT \n",
    "\t\tfighterID, wins as bWins, losses as bLosses, draws as bDraws, \n",
    "\t\theight as bHeight, reach as bReach, weight as bWeight,\n",
    "\t\tstanceID as bStanceID,\n",
    "\t\tsigStrAcc as bSigStrAcc, sigStrDef as bSigStrDef, \n",
    "\t\ttdAcc as bTdAcc, tdDef as bTdDef, avgSubAtt as bAvgSubAtt,\n",
    "\t\tdateOfBirth as bDOB\n",
    "\tFROM dim_Fighter\n",
    ") AS b\n",
    "ON fighterBlueID = b.fighterID\n",
    "\n",
    "SELECT \n",
    "\tfighterID, wins as rWins, losses as rLosses, draws as rDraws, \n",
    "\theight as rHeight, reach as rReach, stanceID as rStanceID,\n",
    "\tsigStrAcc as rSigStrAcc, sigStrDef as rSigStrAcc, \n",
    "\ttdAcc as rTdAcc, tdDef as rTdDef, avgSubAtt as rAvgSubAtt,\n",
    "\tdateOfBirth as rDOB\n",
    "FROM dim_Fighter\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "385af676-10ea-4d71-a651-1645b87cc3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Temp\\ipykernel_18184\\923928451.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['winner'] = df['winner'].replace({'R': 1, 'B': 0})\n"
     ]
    }
   ],
   "source": [
    "df['winner'] = df['winner'].replace({'R': 1, 'B': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d06d601-434b-494c-a1bd-be1574538117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Feature 1  Feature 2  Correlation\n",
      "33    fighterRedID  fighterID     1.000000\n",
      "76   fighterBlueID  fighterID     1.000000\n",
      "278        rWeight    bWeight     0.911139\n",
      "451        bHeight     bReach     0.902922\n",
      "220        rHeight     rReach     0.899711\n",
      "221        rHeight    rWeight     0.794070\n",
      "452        bHeight    bWeight     0.772316\n",
      "243         rReach    rWeight     0.763813\n",
      "276        rWeight    bHeight     0.754381\n",
      "30         fightID       bDOB     0.750220\n",
      "235        rHeight    bWeight     0.747321\n",
      "460         bReach    bWeight     0.745572\n",
      "233        rHeight    bHeight     0.727793\n",
      "277        rWeight     bReach     0.727506\n",
      "16         fightID       rDOB     0.723940\n",
      "257         rReach    bWeight     0.717749\n",
      "234        rHeight     bReach     0.707214\n",
      "255         rReach    bHeight     0.704480\n",
      "256         rReach     bReach     0.688071\n",
      "418          bWins    bLosses     0.675999\n",
      "145          rWins    rLosses     0.654433\n",
      "404           rDOB       bDOB     0.650219\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.6\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df.corr().abs()\n",
    "\n",
    "# Mask the upper triangle and diagonal (to avoid duplicate pairs)\n",
    "mask = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "filtered_corr = corr_matrix.where(mask)\n",
    "\n",
    "# Find pairs with correlation above threshold\n",
    "high_corr_pairs = (\n",
    "    filtered_corr.stack()\n",
    "    .reset_index()\n",
    "    .rename(columns={'level_0': 'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation'})\n",
    "    .query('Correlation > @threshold')\n",
    "    .sort_values(by='Correlation', ascending=False)\n",
    ")\n",
    "\n",
    "print(high_corr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8f0dc1d-ccb6-41e5-bf1d-d9a270ba02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['fightID', 'fighterRedID', 'fighterBlueID', 'fighterID', 'winner']\n",
    "X = df.drop(columns=columns_to_drop)\n",
    "y = df['winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7174c9e5-7997-4a9e-b235-ccb4bb4ea734",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(X.mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f704d6b-f8f3-473d-8cde-0f16ab2657a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f1f808d-b6f5-4a22-9e1e-d443485b4d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "937e9a24-0501-457b-bdd5-2ad82aafe484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.689608636977058\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.23      0.32       477\n",
      "           1       0.71      0.91      0.80      1005\n",
      "\n",
      "    accuracy                           0.69      1482\n",
      "   macro avg       0.63      0.57      0.56      1482\n",
      "weighted avg       0.66      0.69      0.65      1482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "466de74d-c602-4065-bbc6-dd45ce34387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: 1279\n",
      "B: 203\n"
     ]
    }
   ],
   "source": [
    "r_counter = 0\n",
    "b_counter = 0\n",
    "for i in y_pred:\n",
    "    if i == 0:\n",
    "        b_counter += 1\n",
    "    else:\n",
    "        r_counter += 1\n",
    "print('R:', r_counter)\n",
    "print('B:', b_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fbc0efc-e1aa-4867-a51c-6e8d6cdfebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rDOB'] = pd.to_datetime(df['rDOB'].dropna().astype(int).astype(str), format='%Y%m%d', errors='coerce')\n",
    "df['bDOB'] = pd.to_datetime(df['bDOB'].dropna().astype(int).astype(str), format='%Y%m%d', errors='coerce')\n",
    "\n",
    "reference_date = pd.to_datetime('2030-06-30')\n",
    "df['rAge'] = (reference_date - df['rDOB']).dt.days \n",
    "df['bAge'] = (reference_date - df['bDOB']).dt.days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "033b9f1e-903e-415a-9db1-9e218b3188dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reach_diff'] = df['rReach'] - df['bReach']\n",
    "df['height_diff'] = df['rHeight'] - df['bHeight']\n",
    "df['weight_diff'] = df['rWeight'] - df['bWeight']\n",
    "\n",
    "df['sig_str_acc_diff'] = df['rSigStrAcc'] - df['bSigStrAcc']\n",
    "df['sig_str_def_diff'] = df['rSigStrDef'] - df['bSigStrDef']\n",
    "df['td_acc_diff'] = df['rTdAcc'] - df['bTdAcc']\n",
    "df['td_def_diff'] = df['rTdDef'] - df['bTdDef']\n",
    "\n",
    "df['sub_att_diff'] = df['rAvgSubAtt'] - df['bAvgSubAtt']\n",
    "df['wins_diff'] = df['rWins'] - df['bWins']\n",
    "df['losses_diff'] = df['rLosses'] - df['bLosses']\n",
    "df['experience_diff'] = (df['rWins'] + df['rLosses'] + df['rDraws']) - (df['bWins'] + df['bLosses'] + df['bDraws'])\n",
    "df['win_ratio_diff'] = (df['rWins'] / (df['rWins'] + df['rLosses'] + 1)) - (df['bWins'] / (df['bWins'] + df['bLosses'] + 1))\n",
    "\n",
    "df['age_days_diff'] = df['rAge'] - df['bAge']\n",
    "df['age_days_diff'] = df['age_days_diff'].fillna(df['age_days_diff'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "295de613-ed26-4068-8f52-7b0c47bec5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [col for col in df.columns if col.startswith('r') or col.startswith('b')]\n",
    "X = df.drop(columns=columns_to_drop + ['fightID', 'fighterRedID', 'fighterBlueID', 'fighterID', 'winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3f85ede-9af6-40ea-ad9d-4dc933edc9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height_diff</th>\n",
       "      <th>weight_diff</th>\n",
       "      <th>sig_str_acc_diff</th>\n",
       "      <th>sig_str_def_diff</th>\n",
       "      <th>td_acc_diff</th>\n",
       "      <th>td_def_diff</th>\n",
       "      <th>sub_att_diff</th>\n",
       "      <th>wins_diff</th>\n",
       "      <th>losses_diff</th>\n",
       "      <th>experience_diff</th>\n",
       "      <th>win_ratio_diff</th>\n",
       "      <th>age_days_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.074303</td>\n",
       "      <td>-423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>-13</td>\n",
       "      <td>-6</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-36</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>-2133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-4</td>\n",
       "      <td>-36</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-21</td>\n",
       "      <td>-8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2827.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7401</th>\n",
       "      <td>-10</td>\n",
       "      <td>-34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7402</th>\n",
       "      <td>-12</td>\n",
       "      <td>-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403</th>\n",
       "      <td>-13</td>\n",
       "      <td>-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7404</th>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7405</th>\n",
       "      <td>-5</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7406 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      height_diff  weight_diff  sig_str_acc_diff  sig_str_def_diff  \\\n",
       "0              -5           -4                 2                 1   \n",
       "1               8          -13                -6                13   \n",
       "2               2            0                 4                -4   \n",
       "3               5            0                 5                -4   \n",
       "4               0            4                 9               -21   \n",
       "...           ...          ...               ...               ...   \n",
       "7401          -10          -34                 0                 0   \n",
       "7402          -12          -18                 0                 0   \n",
       "7403          -13          -29                 0                 0   \n",
       "7404            9           25                 0                 0   \n",
       "7405           -5           16                 0                 0   \n",
       "\n",
       "      td_acc_diff  td_def_diff  sub_att_diff  wins_diff  losses_diff  \\\n",
       "0               3           27             0          0           -2   \n",
       "1              46            0             0          2           -2   \n",
       "2             -36           -1             0          5            2   \n",
       "3             -36           44             0         -2           -1   \n",
       "4              -8            3             0          8            0   \n",
       "...           ...          ...           ...        ...          ...   \n",
       "7401            0            0             0          1            4   \n",
       "7402            0            0             0          1           -1   \n",
       "7403            0            0             0          1           -2   \n",
       "7404            0            0             0         20           16   \n",
       "7405            0            0             0          2           -1   \n",
       "\n",
       "      experience_diff  win_ratio_diff  age_days_diff  \n",
       "0                  -2        0.074303         -423.0  \n",
       "1                   0        0.181818         1437.0  \n",
       "2                   7        0.005882        -2133.0  \n",
       "3                  -3        0.056818          833.0  \n",
       "4                   7        0.125000         2827.0  \n",
       "...               ...             ...            ...  \n",
       "7401                5        0.142857          124.0  \n",
       "7402                0        0.500000          124.0  \n",
       "7403               -1        0.300000          124.0  \n",
       "7404               36        0.526316          124.0  \n",
       "7405                1        0.500000          124.0  \n",
       "\n",
       "[7406 rows x 12 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5db1af47-852d-4150-b0a3-5d2ce6c5c66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7294197031039136\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.48      0.54       477\n",
      "           1       0.78      0.85      0.81      1005\n",
      "\n",
      "    accuracy                           0.73      1482\n",
      "   macro avg       0.69      0.67      0.67      1482\n",
      "weighted avg       0.72      0.73      0.72      1482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65988bad-0cb2-4923-b543-53fc51d0f37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.680161943319838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.69      0.58       477\n",
      "           1       0.82      0.68      0.74      1005\n",
      "\n",
      "    accuracy                           0.68      1482\n",
      "   macro avg       0.66      0.68      0.66      1482\n",
      "weighted avg       0.72      0.68      0.69      1482\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e505b57-c087-4bdf-b15b-05ec25a6138c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.512253</td>\n",
       "      <td>0.487747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.315347</td>\n",
       "      <td>0.684653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.508782</td>\n",
       "      <td>0.491218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.143495</td>\n",
       "      <td>0.856505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.617012</td>\n",
       "      <td>0.382988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.237572</td>\n",
       "      <td>0.762428</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.519417</td>\n",
       "      <td>0.480583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.475440</td>\n",
       "      <td>0.524560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.441407</td>\n",
       "      <td>0.558593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.608148</td>\n",
       "      <td>0.391852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.755885</td>\n",
       "      <td>0.244115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.430434</td>\n",
       "      <td>0.569566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.294099</td>\n",
       "      <td>0.705901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.436267</td>\n",
       "      <td>0.563733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.297480</td>\n",
       "      <td>0.702520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.091242</td>\n",
       "      <td>0.908758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.470528</td>\n",
       "      <td>0.529472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.423018</td>\n",
       "      <td>0.576982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.713042</td>\n",
       "      <td>0.286958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.557323</td>\n",
       "      <td>0.442677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.034089</td>\n",
       "      <td>0.965911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.762436</td>\n",
       "      <td>0.237564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.297818</td>\n",
       "      <td>0.702182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.483875</td>\n",
       "      <td>0.516125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.486393</td>\n",
       "      <td>0.513607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.711083</td>\n",
       "      <td>0.288917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.671121</td>\n",
       "      <td>0.328879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.634328</td>\n",
       "      <td>0.365672</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.432218</td>\n",
       "      <td>0.567782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.777533</td>\n",
       "      <td>0.222467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.539518</td>\n",
       "      <td>0.460482</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.196480</td>\n",
       "      <td>0.803520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.499033</td>\n",
       "      <td>0.500967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.612279</td>\n",
       "      <td>0.387721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.284225</td>\n",
       "      <td>0.715775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.220801</td>\n",
       "      <td>0.779199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.430730</td>\n",
       "      <td>0.569270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.524200</td>\n",
       "      <td>0.475800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.796662</td>\n",
       "      <td>0.203338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.708778</td>\n",
       "      <td>0.291222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.234035</td>\n",
       "      <td>0.765965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.627955</td>\n",
       "      <td>0.372045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.461699</td>\n",
       "      <td>0.538301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.356873</td>\n",
       "      <td>0.643127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.287720</td>\n",
       "      <td>0.712280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.904985</td>\n",
       "      <td>0.095015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.846670</td>\n",
       "      <td>0.153330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.411479</td>\n",
       "      <td>0.588521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.571180</td>\n",
       "      <td>0.428820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.554226</td>\n",
       "      <td>0.445774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.726042</td>\n",
       "      <td>0.273958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.162405</td>\n",
       "      <td>0.837595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.230608</td>\n",
       "      <td>0.769392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.303650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.747553</td>\n",
       "      <td>0.252447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.240249</td>\n",
       "      <td>0.759751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.159897</td>\n",
       "      <td>0.840103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.827352</td>\n",
       "      <td>0.172648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.516487</td>\n",
       "      <td>0.483513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.291978</td>\n",
       "      <td>0.708022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1  2\n",
       "0   0.512253  0.487747  1\n",
       "1   0.315347  0.684653  1\n",
       "2   0.508782  0.491218  1\n",
       "3   0.143495  0.856505  1\n",
       "4   0.617012  0.382988  0\n",
       "5   0.237572  0.762428  1\n",
       "6   0.519417  0.480583  1\n",
       "7   0.475440  0.524560  1\n",
       "8   0.441407  0.558593  1\n",
       "9   0.608148  0.391852  0\n",
       "10  0.755885  0.244115  1\n",
       "11  0.430434  0.569566  1\n",
       "12  0.294099  0.705901  1\n",
       "13  0.436267  0.563733  1\n",
       "14  0.297480  0.702520  1\n",
       "15  0.091242  0.908758  1\n",
       "16  0.470528  0.529472  0\n",
       "17  0.423018  0.576982  0\n",
       "18  0.713042  0.286958  0\n",
       "19  0.557323  0.442677  1\n",
       "20  0.034089  0.965911  1\n",
       "21  0.762436  0.237564  1\n",
       "22  0.297818  0.702182  1\n",
       "23  0.483875  0.516125  0\n",
       "24  0.486393  0.513607  1\n",
       "25  0.711083  0.288917  1\n",
       "26  0.671121  0.328879  0\n",
       "27  0.634328  0.365672  1\n",
       "28  0.432218  0.567782  1\n",
       "29  0.777533  0.222467  0\n",
       "30  0.539518  0.460482  1\n",
       "31  0.196480  0.803520  1\n",
       "32  0.499033  0.500967  0\n",
       "33  0.612279  0.387721  0\n",
       "34  0.284225  0.715775  1\n",
       "35  0.220801  0.779199  1\n",
       "36  0.430730  0.569270  0\n",
       "37  0.524200  0.475800  0\n",
       "38  0.796662  0.203338  0\n",
       "39  0.708778  0.291222  1\n",
       "40  0.234035  0.765965  1\n",
       "41  0.627955  0.372045  1\n",
       "42  0.461699  0.538301  0\n",
       "43  0.356873  0.643127  1\n",
       "44  0.287720  0.712280  1\n",
       "45  0.904985  0.095015  0\n",
       "46  0.846670  0.153330  0\n",
       "47  0.411479  0.588521  1\n",
       "48  0.571180  0.428820  0\n",
       "49  0.554226  0.445774  1\n",
       "50  0.726042  0.273958  0\n",
       "51  0.162405  0.837595  0\n",
       "52  0.230608  0.769392  1\n",
       "53  0.696350  0.303650  0\n",
       "54  0.747553  0.252447  0\n",
       "55  0.240249  0.759751  1\n",
       "56  0.159897  0.840103  1\n",
       "57  0.827352  0.172648  0\n",
       "58  0.516487  0.483513  1\n",
       "59  0.291978  0.708022  1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model.predict_proba(X_test)\n",
    "pd.DataFrame([(probs[i, 0], probs[i, 1], y_test.iat[i]) for i in range(len(probs))]).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bca97a5f-9290-427e-b32b-8c3bd0ad233e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height_diff</th>\n",
       "      <th>weight_diff</th>\n",
       "      <th>sig_str_acc_diff</th>\n",
       "      <th>sig_str_def_diff</th>\n",
       "      <th>td_acc_diff</th>\n",
       "      <th>td_def_diff</th>\n",
       "      <th>sub_att_diff</th>\n",
       "      <th>wins_diff</th>\n",
       "      <th>losses_diff</th>\n",
       "      <th>experience_diff</th>\n",
       "      <th>win_ratio_diff</th>\n",
       "      <th>age_days_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>height_diff</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207559</td>\n",
       "      <td>0.062805</td>\n",
       "      <td>-0.054911</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>-0.017184</td>\n",
       "      <td>0.108693</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>-0.011764</td>\n",
       "      <td>-0.001216</td>\n",
       "      <td>0.037137</td>\n",
       "      <td>-0.131506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_diff</th>\n",
       "      <td>0.207559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015226</td>\n",
       "      <td>-0.082201</td>\n",
       "      <td>0.014302</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>-0.013093</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.027859</td>\n",
       "      <td>-0.026153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_str_acc_diff</th>\n",
       "      <td>0.062805</td>\n",
       "      <td>-0.015226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.284044</td>\n",
       "      <td>0.262984</td>\n",
       "      <td>0.171683</td>\n",
       "      <td>0.078284</td>\n",
       "      <td>0.065711</td>\n",
       "      <td>-0.043695</td>\n",
       "      <td>0.033616</td>\n",
       "      <td>0.239879</td>\n",
       "      <td>-0.048848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_str_def_diff</th>\n",
       "      <td>-0.054911</td>\n",
       "      <td>-0.082201</td>\n",
       "      <td>0.284044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.208152</td>\n",
       "      <td>0.326289</td>\n",
       "      <td>-0.118631</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.064477</td>\n",
       "      <td>0.189678</td>\n",
       "      <td>0.019701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>td_acc_diff</th>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.014302</td>\n",
       "      <td>0.262984</td>\n",
       "      <td>0.208152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263955</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.069972</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.054389</td>\n",
       "      <td>0.127367</td>\n",
       "      <td>-0.057492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>td_def_diff</th>\n",
       "      <td>-0.017184</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.171683</td>\n",
       "      <td>0.326289</td>\n",
       "      <td>0.263955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.212548</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.033830</td>\n",
       "      <td>0.132426</td>\n",
       "      <td>-0.089048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_att_diff</th>\n",
       "      <td>0.108693</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.078284</td>\n",
       "      <td>-0.118631</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>-0.212548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>-0.051649</td>\n",
       "      <td>-0.016797</td>\n",
       "      <td>0.070626</td>\n",
       "      <td>-0.026237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wins_diff</th>\n",
       "      <td>0.004973</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>0.065711</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.069972</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.605083</td>\n",
       "      <td>0.956136</td>\n",
       "      <td>0.302849</td>\n",
       "      <td>0.086465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses_diff</th>\n",
       "      <td>-0.011764</td>\n",
       "      <td>-0.013093</td>\n",
       "      <td>-0.043695</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>-0.051649</td>\n",
       "      <td>0.605083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807687</td>\n",
       "      <td>-0.399137</td>\n",
       "      <td>0.246735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience_diff</th>\n",
       "      <td>-0.001216</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.033616</td>\n",
       "      <td>0.064477</td>\n",
       "      <td>0.054389</td>\n",
       "      <td>0.033830</td>\n",
       "      <td>-0.016797</td>\n",
       "      <td>0.956136</td>\n",
       "      <td>0.807687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080178</td>\n",
       "      <td>0.154933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win_ratio_diff</th>\n",
       "      <td>0.037137</td>\n",
       "      <td>0.027859</td>\n",
       "      <td>0.239879</td>\n",
       "      <td>0.189678</td>\n",
       "      <td>0.127367</td>\n",
       "      <td>0.132426</td>\n",
       "      <td>0.070626</td>\n",
       "      <td>0.302849</td>\n",
       "      <td>-0.399137</td>\n",
       "      <td>0.080178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.237595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_days_diff</th>\n",
       "      <td>-0.131506</td>\n",
       "      <td>-0.026153</td>\n",
       "      <td>-0.048848</td>\n",
       "      <td>0.019701</td>\n",
       "      <td>-0.057492</td>\n",
       "      <td>-0.089048</td>\n",
       "      <td>-0.026237</td>\n",
       "      <td>0.086465</td>\n",
       "      <td>0.246735</td>\n",
       "      <td>0.154933</td>\n",
       "      <td>-0.237595</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  height_diff  weight_diff  sig_str_acc_diff  \\\n",
       "height_diff          1.000000     0.207559          0.062805   \n",
       "weight_diff          0.207559     1.000000         -0.015226   \n",
       "sig_str_acc_diff     0.062805    -0.015226          1.000000   \n",
       "sig_str_def_diff    -0.054911    -0.082201          0.284044   \n",
       "td_acc_diff          0.036200     0.014302          0.262984   \n",
       "td_def_diff         -0.017184     0.002991          0.171683   \n",
       "sub_att_diff         0.108693     0.003485          0.078284   \n",
       "wins_diff            0.004973     0.016047          0.065711   \n",
       "losses_diff         -0.011764    -0.013093         -0.043695   \n",
       "experience_diff     -0.001216     0.003494          0.033616   \n",
       "win_ratio_diff       0.037137     0.027859          0.239879   \n",
       "age_days_diff       -0.131506    -0.026153         -0.048848   \n",
       "\n",
       "                  sig_str_def_diff  td_acc_diff  td_def_diff  sub_att_diff  \\\n",
       "height_diff              -0.054911     0.036200    -0.017184      0.108693   \n",
       "weight_diff              -0.082201     0.014302     0.002991      0.003485   \n",
       "sig_str_acc_diff          0.284044     0.262984     0.171683      0.078284   \n",
       "sig_str_def_diff          1.000000     0.208152     0.326289     -0.118631   \n",
       "td_acc_diff               0.208152     1.000000     0.263955      0.007777   \n",
       "td_def_diff               0.326289     0.263955     1.000000     -0.212548   \n",
       "sub_att_diff             -0.118631     0.007777    -0.212548      1.000000   \n",
       "wins_diff                 0.082474     0.069972     0.045200      0.003411   \n",
       "losses_diff               0.007078     0.009346     0.001956     -0.051649   \n",
       "experience_diff           0.064477     0.054389     0.033830     -0.016797   \n",
       "win_ratio_diff            0.189678     0.127367     0.132426      0.070626   \n",
       "age_days_diff             0.019701    -0.057492    -0.089048     -0.026237   \n",
       "\n",
       "                  wins_diff  losses_diff  experience_diff  win_ratio_diff  \\\n",
       "height_diff        0.004973    -0.011764        -0.001216        0.037137   \n",
       "weight_diff        0.016047    -0.013093         0.003494        0.027859   \n",
       "sig_str_acc_diff   0.065711    -0.043695         0.033616        0.239879   \n",
       "sig_str_def_diff   0.082474     0.007078         0.064477        0.189678   \n",
       "td_acc_diff        0.069972     0.009346         0.054389        0.127367   \n",
       "td_def_diff        0.045200     0.001956         0.033830        0.132426   \n",
       "sub_att_diff       0.003411    -0.051649        -0.016797        0.070626   \n",
       "wins_diff          1.000000     0.605083         0.956136        0.302849   \n",
       "losses_diff        0.605083     1.000000         0.807687       -0.399137   \n",
       "experience_diff    0.956136     0.807687         1.000000        0.080178   \n",
       "win_ratio_diff     0.302849    -0.399137         0.080178        1.000000   \n",
       "age_days_diff      0.086465     0.246735         0.154933       -0.237595   \n",
       "\n",
       "                  age_days_diff  \n",
       "height_diff           -0.131506  \n",
       "weight_diff           -0.026153  \n",
       "sig_str_acc_diff      -0.048848  \n",
       "sig_str_def_diff       0.019701  \n",
       "td_acc_diff           -0.057492  \n",
       "td_def_diff           -0.089048  \n",
       "sub_att_diff          -0.026237  \n",
       "wins_diff              0.086465  \n",
       "losses_diff            0.246735  \n",
       "experience_diff        0.154933  \n",
       "win_ratio_diff        -0.237595  \n",
       "age_days_diff          1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a449d15c-aad1-46b7-9869-169023525998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN params: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_grid = GridSearchCV(knn, knn_params, scoring='accuracy')\n",
    "knn_grid.fit(X_train, y_train)\n",
    "print(\"Best KNN params:\", knn_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44bb41cc-7e9d-45c4-8270-1937a1fdd31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655195681511471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.35      0.39       477\n",
      "           1       0.72      0.80      0.76      1005\n",
      "\n",
      "    accuracy                           0.66      1482\n",
      "   macro avg       0.59      0.57      0.58      1482\n",
      "weighted avg       0.64      0.66      0.64      1482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = knn_grid.best_estimator_\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "565ecb16-8102-4091-83bd-aa21971dc15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "print(\"Best Random Forest params:\", rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7595e69c-a9da-4172-8c6c-e749e04c7af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7300944669365722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.46      0.52       477\n",
      "           1       0.77      0.86      0.81      1005\n",
      "\n",
      "    accuracy                           0.73      1482\n",
      "   macro avg       0.69      0.66      0.67      1482\n",
      "weighted avg       0.72      0.73      0.72      1482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = rf_grid.best_estimator_\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "865ccea3-71f6-4c41-8f97-37fe88bcf412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Svetlana Nazarko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression params: {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_params = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear', 'saga'],\n",
    "    'max_iter': [100, 200, 1000]\n",
    "}\n",
    "\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg_grid = GridSearchCV(logreg, logreg_params, cv=5, scoring='accuracy')\n",
    "logreg_grid.fit(X_train, y_train)\n",
    "print(\"Best Logistic Regression params:\", logreg_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a479d330-0d0f-4936-834c-93adcf80bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7314439946018894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.44      0.51       477\n",
      "           1       0.77      0.87      0.81      1005\n",
      "\n",
      "    accuracy                           0.73      1482\n",
      "   macro avg       0.69      0.65      0.66      1482\n",
      "weighted avg       0.72      0.73      0.72      1482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = logreg_grid.best_estimator_\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da4093-9c14-43cd-8db1-5db191df4be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
